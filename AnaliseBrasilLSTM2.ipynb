{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELATÓRIO SOBRE CORONA VÍRUS NO BRASIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"brazil_covid19_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altere a data aqui, quando conseguir o documento com dados de outras data. Esse filtro foi criado para evitar pegar dados com valor zero, por falta de informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cases\n",
       "date             \n",
       "2020-01-30      0\n",
       "2020-01-31      0\n",
       "2020-02-01      0\n",
       "2020-02-02      0\n",
       "2020-02-03      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter_date = df['date'] < '2020-03-19'\n",
    "#df = df[filter_date]\n",
    "state =  df.drop('state', axis=1).groupby('date').sum().drop('deaths', axis=1)\n",
    "state.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionaremos todos os algoritmo LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day=1, Predicted=4016.405447, Expected=3903.000000\n",
      "Day=2, Predicted=4372.753535, Expected=4256.000000\n",
      "Day=3, Predicted=4064.261419, Expected=4579.000000\n",
      "Day=4, Predicted=4434.547971, Expected=5717.000000\n",
      "Day=5, Predicted=6048.078674, Expected=6836.000000\n",
      "Day=6, Predicted=7347.164277, Expected=7910.000000\n",
      "Day=7, Predicted=8447.405730, Expected=9056.000000\n",
      "Day=8, Predicted=9596.206953, Expected=10278.000000\n",
      "Day=9, Predicted=10816.016428, Expected=11130.000000\n",
      "Day=10, Predicted=11655.620685, Expected=12056.000000\n",
      "1) Test RMSE: 629.909\n",
      "1\n",
      "-Day=69, Predicted=12541.995003\n",
      "             rmse\n",
      "count    1.000000\n",
      "mean   629.908985\n",
      "std           NaN\n",
      "min    629.908985\n",
      "25%    629.908985\n",
      "50%    629.908985\n",
      "75%    629.908985\n",
      "max    629.908985\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAD6lJREFUeJzt3X+s3XV9x/HnazYlo3+0GvQKlNmalTowYrojo1kk13QTZYudG3NN/IlLqku98Y8lpg1zM3NdlrnFXFw0diCBpBsjjc7GkUZxOftLLhapaH8wmyLrbajWLJhdSFp+vPfH/RoPWHu/pff20g/PR3LT7/dzPt+ez0kOz/vly/ccUlVIktr1K4u9AEnSwjL0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjVuy2AsAuOSSS2rVqlWLvQzptJ588kmWLVu22MuQfsGDDz74k6p69VzzXhKhX7VqFXv37l3sZUinNRwOGR8fX+xlSL8gyWN95nnpRpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIa1yv0SVYk2ZXkUJKDSdZ34xPd2P4kfz8yf1uSw0keSXLDQi1ekjS3vl+BMAnsqaqbkiwFLk7yNmAjcE1VnUzyGoAkVwGbgKuBy4D7klxZVc8uwPolSXOY84w+yXLgeuB2gKo6VVVPAH8G/F1VnezGf9wdshG4u6pOVtWjwGHg2oVYvCRpbn0u3awGTgB3JHkoyW1JlgFXAm9NMpXkv5K8pZt/OXB05PjpbkyStAj6XLpZAqwDJqpqKskksLUbfxVwHfAW4J4kr+/7xEk2A5sBxsbGGA6HZ7l06fyYmZnx/akLWp/QTwPTVTXV7e9iNvTTwJerqoAHkjwHXAIcA64YOX5lN/Y8VbUD2AEwGAzKr4HVS5VfU6wL3ZyXbqrqOHA0ydpuaANwAPh34G0ASa4ElgI/AXYDm5JclGQ1sAZ4YAHWLknqoe9dNxPAzu6OmyPAzcCTwJeSfB84BXywO7vfn+QeZn8ZPANs8Y4bSVo8vUJfVfuAwWkeet8vmb8d2H4O65IkzRM/GStJjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktQ4Qy9JjTP0ktS4XqFPsiLJriSHkhxMsj7Jp5IcS7Kv+7lxZP62JIeTPJLkhoVbviRpLkt6zpsE9lTVTUmWAhcDNwCfrap/GJ2Y5CpgE3A1cBlwX5Irq+rZeVy3JKmnOc/okywHrgduB6iqU1X1xBkO2QjcXVUnq+pR4DBw7XwsVpJ09vpculkNnADuSPJQktuSLOse+1iSh5N8Kckru7HLgaMjx093Y5KkRdDn0s0SYB0wUVVTSSaBrcA/AZ8GqvvzH4EP933iJJuBzQBjY2MMh8OzW7l0nszMzPj+1AWtT+ingemqmur2dwFbq+pHP5uQ5J+Br3W7x4ArRo5f2Y09T1XtAHYADAaDGh8fP+vFS+fDcDjE96cuZHNeuqmq48DRJGu7oQ3AgSSXjkx7N/D9bns3sCnJRUlWA2uAB+ZxzZKks9D3rpsJYGd3x80R4Gbg1iRvZvbSzQ+BjwBU1f4k9wAHgGeALd5xI0mLp1foq2ofMHjB8PvPMH87sP0c1iVJmid+MlaSGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGtcr9ElWJNmV5FCSg0nWjzz250kqySXdfpLcmuRwkoeTrFuoxUuS5rak57xJYE9V3ZRkKXAxQJIrgLcD/zMy953Amu7nt4AvdH9KkhbBnGf0SZYD1wO3A1TVqap6onv4s8AngBo5ZCNwV826H1iR5NL5XbYkqa8+Z/SrgRPAHUmuAR4EPg78DnCsqr6bZHT+5cDRkf3pbuzx0UlJNgObAcbGxhgOhy/yJUgLa2ZmxvenLmh9Qr8EWAdMVNVUkkngU8ye5b/9xT5xVe0AdgAMBoMaHx9/sX+VtKCGwyG+P3Uh6/MfY6eB6aqa6vZ3MRv+1cB3k/wQWAl8J8lrgWPAFSPHr+zGJEmLYM7QV9Vx4GiStd3QBuA7VfWaqlpVVauY/WWwrpu7G/hAd/fNdcBPq+rx0/7lkqQF1/eumwlgZ3fHzRHg5jPMvRe4ETgMPDXHXEnSAusV+qraBwzO8Piqke0CtpzzyiRJ88JPxkpS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDXO0EtS4wy9JDWuV+iTrEiyK8mhJAeTrE/y6SQPJ9mX5OtJLuvmJsmtSQ53j69b2JcgSTqTvmf0k8CeqnoDcA1wEPhMVb2pqt4MfA34y27uO4E13c9m4Avzu2RJ0tlYMteEJMuB64EPAVTVKeDUC6YtA6rb3gjcVVUF3N/928ClVfX4vK1aktRbnzP61cAJ4I4kDyW5LckygCTbkxwF3svPz+gvB46OHD/djUmSFsGcZ/TdnHXARFVNJZkEtgKfrKpbgFuSbAM+BvxV3ydOspnZSzuMjY0xHA7Pdu16mZt4bOL8PdmdC/8Un3vd5xb+SfSylNkrLGeYkLwWuL+qVnX7bwW2VtXvjcz5NeDeqnpjki8Cw6r61+6xR4DxM126GQwGtXfv3nN+MdJCGA6HjI+PL/YypF+Q5MGqGsw1b85LN1V1HDiaZG03tAE4kGTNyLSNwKFuezfwge7um+uAn3p9XpIWT59LNwATwM4kS4EjwM3AbV38nwMeAz7azb0XuBE4DDzVzZUkLZJeoa+qfcAL//Xgj37J3AK2nOO6JEnzxE/GSlLjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjeoU+yYoku5IcSnIwyfokn+n2H07ylSQrRuZvS3I4ySNJbli45UuS5tL3jH4S2FNVbwCuAQ4C3wDeWFVvAv4b2AaQ5CpgE3A18A7g80leMd8LlyT1M2fokywHrgduB6iqU1X1RFV9vaqe6abdD6zstjcCd1fVyap6FDgMXDv/S5ck9bGkx5zVwAngjiTXAA8CH6+qJ0fmfBj4t277cmbD/zPT3djzJNkMbAYYGxtjOBye9eKl82FmZsb3py5ofUK/BFgHTFTVVJJJYCvwSYAktwDPADvP5omragewA2AwGNT4+PjZHC6dN8PhEN+fupD1uUY/DUxX1VS3v4vZ8JPkQ8DvA++tquoePwZcMXL8ym5MkrQI5gx9VR0HjiZZ2w1tAA4keQfwCeBdVfXUyCG7gU1JLkqyGlgDPDDP65Yk9dTn0g3ABLAzyVLgCHAz8G3gIuAbSQDur6qPVtX+JPcAB5i9pLOlqp6d/6VLkvroFfqq2gcMXjD862eYvx3Yfg7rkiTNEz8ZK0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1LheoU+yIsmuJIeSHEyyPskfJ9mf5LkkgxfM35bkcJJHktywMEuXJPWxpOe8SWBPVd2UZClwMfAE8IfAF0cnJrkK2ARcDVwG3Jfkyqp6dv6WLUnqa87QJ1kOXA98CKCqTgGnmA09SV54yEbg7qo6CTya5DBwLfCteVu1JKm3PpduVgMngDuSPJTktiTLzjD/cuDoyP50NyZJWgR9Lt0sAdYBE1U1lWQS2Ap88lyeOMlmYDPA2NgYw+HwXP46acHMzMz4/tQFrU/op4Hpqprq9ncxG/pf5hhwxcj+ym7seapqB7ADYDAY1Pj4eJ/1SufdcDjE96cuZHNeuqmq48DRJGu7oQ3AgTMcshvYlOSiJKuBNcAD57xSSdKL0veumwlgZ3fHzRHg5iTvBj4HvBr4jyT7quqGqtqf5B5mfxk8A2zxjhtJWjy9Ql9V+4DBC4a/0v2cbv52YPu5LU2SNB/8ZKwkNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjeoU+yYoku5IcSnIwyfokr0ryjSQ/6P58ZTc3SW5NcjjJw0nWLexLkCSdSd8z+klgT1W9AbgGOAhsBb5ZVWuAb3b7AO8E1nQ/m4EvzOuKJUlnZc7QJ1kOXA/cDlBVp6rqCWAjcGc37U7gD7rtjcBdNet+YEWSS+d95ZKkXvqc0a8GTgB3JHkoyW1JlgFjVfV4N+c4MNZtXw4cHTl+uhuTJC2CJT3nrAMmqmoqySQ/v0wDQFVVkjqbJ06ymdlLO4yNjTEcDs/mcOm8mZmZ8f2pC1qf0E8D01U11e3vYjb0P0pyaVU93l2a+XH3+DHgipHjV3Zjz1NVO4AdAIPBoMbHx1/cK5AW2HA4xPenLmRzXrqpquPA0SRru6ENwAFgN/DBbuyDwFe77d3AB7q7b64DfjpyiUeSdJ71OaMHmAB2JlkKHAFuZvaXxD1J/hR4DHhPN/de4EbgMPBUN1eStEh6hb6q9gGD0zy04TRzC9hyjuuSJM0TPxkrSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUuMx+Y8EiLyI5wez35UgvRZcAP1nsRUin8bqqevVck14SoZdeypLsrarTfdeTdEHw0o0kNc7QS1LjDL00tx2LvQDpXHiNXpIa5xm9JDXO0EtS4wy9Xta6/4m9/xyoab7B9bKTZFWSR5LcBXwfeDbJZ5LsT3JfkmuTDJMcSfKu7pirkzyQZF+Sh5Os6cbfNzL+xSSvWMzXJp2OodfL1Rrg81V1dbf/n932/wF/A/wu8G7gr7vHPwpMVtWbgQEwneQ3gD8BfrsbfxZ473l8DVIvSxZ7AdIieayq7u+2TwF7uu3vASer6ukk3wNWdePfAm5JshL4clX9IMkG4DeBbycB+FXgx+frBUh9GXq9XD05sv10/fw+4+eAkwBV9VySJd32vySZAn4PuDfJR4AAd1bVtvO4bumseelG6iHJ64EjVXUr8FXgTcA3gZuSvKab86okr1vEZUqn5Rm91M97gPcneRo4DvxtVf1vkr8Avt7dufM0sAW/iVUvMX4yVpIa56UbSWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxv0/p44A/ePvpWkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Codigo original de https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "# Alterado por Nathana\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from datetime import date\n",
    "\n",
    "import numpy\n",
    " \n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    " \n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    " \n",
    "# load dataset\n",
    "series = state\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    " \n",
    "value_test = 10    \n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-value_test], supervised_values[-value_test:]\n",
    " \n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    " \n",
    "# repeat experiment\n",
    "repeats = 1\n",
    "error_scores = list()\n",
    "for r in range(repeats):\n",
    "    # fit the model\n",
    "    lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "    # forecast the entire training dataset to build up state for forecasting\n",
    "    train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "    lstm_model.predict(train_reshaped, batch_size=1)\n",
    "    # walk-forward validation on the test data\n",
    "    predictions = list()\n",
    "    for i in range(len(test_scaled)):\n",
    "        # make one-step forecast\n",
    "        X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "        yhat = forecast_lstm(lstm_model, 1, X)\n",
    "        yhat = invert_scale(scaler, X, yhat)\n",
    "        yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "        expected = raw_values[len(train) + i + 1]\n",
    "        print('Day=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "    # report performance\n",
    "    rmse = sqrt(mean_squared_error(raw_values[-value_test:], predictions))\n",
    "    print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "    error_scores.append(rmse)\n",
    " \n",
    "# prevendo os dados\n",
    "# Pega a ultima data que se foi testado\n",
    "last_date = series['cases'].index\n",
    "last_date = last_date[-1]\n",
    "# Testa com o dia de hoje\n",
    "currently_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "new_date = datetime.strptime(currently_date,\"%Y-%m-%d\") - datetime.strptime(last_date,\"%Y-%m-%d\") \n",
    "print(new_date.days)\n",
    "\n",
    "\n",
    "# Faz a data que queremos descobrir menos a informata para ter numero de dias\n",
    "predict_values = new_date.days\n",
    "size_raw = len(raw_values)\n",
    "#size_vector = predict_values - size_raw + 1\n",
    "\n",
    "for i in range(0,predict_values):\n",
    "    count_day =  np.asarray([[size_raw + i + 1]])\n",
    "    count_day = count_day.reshape(count_day.shape[0], count_day.shape[1])\n",
    "    yhat = forecast_lstm(lstm_model, 1, count_day)\n",
    "    yhat = invert_scale(scaler, count_day, yhat)\n",
    "    yhat = inverse_difference(raw_values, yhat, 1)\n",
    "    print('-Day=%d, Predicted=%f' %  (size_raw+i+1, yhat))\n",
    "    raw_values = np.append(raw_values, yhat)\n",
    "\n",
    "\n",
    "# summarize results\n",
    "results = DataFrame()\n",
    "results['rmse'] = error_scores\n",
    "print(results.describe())\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
